

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" >
<head id="Head1"><title>
	Cornell Virtual Workshop
</title><meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" /><meta http-equiv="Content-Language" content="en-us" /><link rel="stylesheet" type="text/css" media="screen" href="styles/main.css" />
		        <script type="text/javascript" src="swfobject.js"></script>
    <link rel="shortcut icon" href="https://cvw.cac.cornell.edu/favicon.ico" type="image/icon" /></head>

<body>   

<!-- for text-based browsers -->  <div id="skipnav"><a href="#content">Skip to main content</a></div>

<hr class="CU" />

<form method="post" action="./topics" id="form1">
<div class="aspNetHidden">
<input type="hidden" name="__EVENTTARGET" id="__EVENTTARGET" value="" />
<input type="hidden" name="__EVENTARGUMENT" id="__EVENTARGUMENT" value="" />
<input type="hidden" name="__VIEWSTATE" id="__VIEWSTATE" value="YET010g1ZlZmYCMl6dv8Pw63m1ep+E3yLFHXm0b8RnJmVtYo+Q68RKz//hgQmg3gVTI3auQYXbOUGrpmZjYlNBDYK31dil3OWPyVzLvwtkIZv3PLwfn3ZDVJaOT0+CGsg3Avk5eKzxkQLIEk1Tex+TGm5ijwRrgGnMWmbUnqcBX36dWiFddoETs3qZftcOW5upOIRiuvRtWzCJM8judzZrAvkK9O+eZG7SUgfthS1VQDtnbmzKUEJnLF/BGpNe+pxs53VQmVftSxgKnLedCojKdDJxRamhrnatygwGHKzLomM+/DsPS6YgmWbDh5GfO5UZVKavjUVxv7K/+LupTMG7QNpcdWnfLTzJ8KWUdoVCJKViaWnTuJoV0C7FXIVGFJnvEQZs0PZpOvR//b89Bb8mVIWm+sgcP6j9ne6Haiw1h9iCdA3LuTMeZEBVINPRMThTvs1ViTVIqWHbVwQtopjKxi2iVmrhrDvYXWDjhQnUNLt0ckM5VMp3CFwaHzzTroL4YjByaS0+rreBHi2eBa81PKgJVY7E81kTT37BcoQQ0GPHmHxEAEdwFZe96ynmRlVmrkfLUshRyUCoUa2aH8X4LmhDgFl/iHpQcGLFITxAoKDl2Xq8QwqUiyxNBG2HX2" />
</div>

<script type="text/javascript">
//<![CDATA[
var theForm = document.forms['form1'];
if (!theForm) {
    theForm = document.form1;
}
function __doPostBack(eventTarget, eventArgument) {
    if (!theForm.onsubmit || (theForm.onsubmit() != false)) {
        theForm.__EVENTTARGET.value = eventTarget;
        theForm.__EVENTARGUMENT.value = eventArgument;
        theForm.submit();
    }
}
//]]>
</script>


<div class="aspNetHidden">

	<input type="hidden" name="__VIEWSTATEGENERATOR" id="__VIEWSTATEGENERATOR" value="4710822C" />
	<input type="hidden" name="__EVENTVALIDATION" id="__EVENTVALIDATION" value="eHjHPW+tNOwkoa0bGeE2hpnlDmQHHQBBg68jr1rbg1N7Z8fI7nUFZ4kw1e/ccLklvNLIhSE4LYXkagR58xYev/alCPhDvkmdJe/TIZWKshAcArFyq9W6SUOgw16N7U+u" />
</div>

<div id="header">	
  
	<div id="navigation">
		<ul>
            <span id="lblNavBar"><li><a href='/default.aspx'>Home</a></li><li><div id='current'><a href='/topics.aspx'>Topics</a></div></li><li><a href='/main/reference.aspx'>Reference</a></li><li><a href='/main/glossary.aspx'>Glossary</a></li><li><a href='/main/help.aspx'>Help</a></li><li><a href='/main/notebook.aspx'>Notebook</a></li></span>
		</ul>     
	</div>
	<div id="TitleBarBg"> 
	<div id="Containment">
	    <div id="TitleBar">
	        <div id="identity"><h1>Cornell Virtual Workshop</h1> </div>
	            </div>
            <div id="LogInOut">Welcome guest 
                <br /><a id="LinkBtnOauth2Login" href="javascript:__doPostBack(&#39;ctl00$LinkBtnOauth2Login&#39;,&#39;&#39;)">Log in (Globus)</a><br /><span id="lblLoginPage"><a href='/Registration/'>Log in (other)</a></span></div>
                
    </div>
    </div>
</div>

<div id="wrap">

<!-- The content div contains the main content of the page -->
<div id="content">
<hr class="CU" />

<!-- BEGIN MAIN -->
<div id="main">
<div id="widebluebox">

    <h2>Topics</h2>
    

    <p><a href="Linux/">An Introduction to Linux</a><br />
    This tutorial is for the beginning Linux user, intended to get the user acquainted with some of the basic principles of the Linux operating system.</p>

    <center><hr width="75%" /><h3>Programming Languages</h3></center>

   <p><a href="Cintro/">An Introduction to C Programming</a><br />
    This module is for the beginning programmer who wants to learn the effective use of the C language. If you have never programmed before you can also use this document to learn the basic concepts of programming; however, you may want to have other references to guide you.</p>

   <p><a href="Fintro/">An Introduction to Fortran Programming</a><br />
    This module is for the beginning programmer who is interested in learning the effective use of the Fortran language. If you have never programmed before you can also use this document to learn the basic concepts of programming; however, you may want to have other references to guide you.</p>

        <p><a href="pythonintro/">An Introduction to Python</a><br />
    Python is a programming language designed with ease of programming and readable code as its foremost goals. 
 Python has risen to prominence in scientific computing as the ideal tool for doing data conversions, scripting parameter studies, and in facilitating the scientific workflow.
In this online course, a quick overview of the language is presented, along with a few tricks to maximize the utility of Python for engineering and science modeling. 
    </p>
 

    <p><a href="python/">Python for High Performance</a><br />
    While Python is a scripting language, it has plenty of facilities for high performance computing. This article covers some of its features and libraries that are particularly helpful when moving scientific code to a large cluster resource. It also includes specific recipes for compilation and execution on the TACC clusters.</p>
 
 
    <p><b>Python for Data Science</b>
         introduces a variety of useful tools and techniques for doing data science using the Python programming language. Datasets from different application domains are examined to illustrate the use of these tools in action.<br />
        <a href="PyDataSci1/">Python for Data Science - Part 1: Data Processing and Visualization</a>: 
        Part 1 focuses on packages and methods supporting data import, preprocessing, and visualization.  <br />
        <a href="PyDataSci2/">Python for Data Science - Part 2: Data Modeling and Machine Learning</a>: 
        Part 2 focuses on packages and methods supporting data modeling, statistics, machine learning, and interactive visualization.</p>
 
 
     <p><a href="R/">Introduction to R</a><br />
    This module will serve as an introduction to R, briefly covering the basic syntax of the language and illustrating some of its data handling and statistical capabilities. The focus will be on how to run R in various environments and especially how to run R in parallel.</p>
 


    <p><a href="scripting/">Balancing Scripts and Compiled Code in Scientific Applications</a><br />
    This module works through examples of scientific application code written in a mix of scripting languages and C, C++ or Fortran code in order to evaluate where, within an application, scripting is a good choice.</p>
 



   <p><a href="matlab/">MATLAB Programming</a><br /> 
   MATLAB provides matrix manipulation, plotting, and general purpose scientific programming capability, as well as functionality  through specialized "toolboxes" such as the Optimization toolbox, the Statistics toolbox, the Signal Processing toolbox, the Image Processing Toolbox, etc.</p>


   

   <p><a href="gpu/">Introduction to GPGPU and CUDA Programming</a><br /> 
   This module briefly covers general GPU topics such as hardware architecture and application speedup, followed by an introductory section of CUDA programming and performance optimization topics.</p>




         <center><h3>Computing Resources</h3></center>

     <p><a href="frontera/">Getting Started on Frontera</a><br />
    Frontera is  the largest academic supercomputer in the world, located at The University of Texas at Austin's Texas Advanced Computing Center (TACC).
    Frontera is tailored towards the very largest of scientific computing projects.  This quick-start guide covers an architecture overview, the user environment, file storage and data movement, 
    compiling code, and running jobs.</p>


    

        <p><a href="Environment/">Stampede2 Environment</a><br />
    This topic provides the information you need to start working on Stampede2 and includes sections on logging on to Stampede2, 
    the hardware/software environment, moving files to Stampede2, compiling, and using the SLURM batch system.</p>

       <p><a href="slurm/">Advanced SLURM</a><br /> 
   SLURM (Simple Linux Utility for Resource Management) is a group of utilities used for managing workloads on compute clusters. 
   On Stampede2, all jobs executed on the compute nodes are managed by SLURM. 

This module is for users who are already familiar with the process of submitting jobs via SLURM, but whose needs go beyond submitting simple batch files or interactive jobs. 
   </p>

    <p><a href="ClusterArch/">Introduction to Advanced Cluster Architectures</a><br />
Advanced clusters for High Performance Computing are powered by a large number of multi-core processors, abundant memory and cache, and fast interconnects.  The Stampede2 and Frontera systems at TACC are two such systems, each constructed using CPUs from the Intel Scalable Processor line.  This topic introduces some of the key characteristics of these clusters and their processors, as well as methods and tools to use them effectively.</p>

        <p><a href="KNLStart/">Getting Started on KNL</a><br />
    The second generation of the Intel Xeon Phi product line opens up a range of features and options that make it more adaptable to different HPC workloads. 
            This topic presents the salient characteristics of the Intel Knights Landing (KNL) microprocessor architecture and how to use them effectively. 
            In the spirit of a workshop, the presentation is interspersed with short, relevant exercises to highlight the features as they are discussed.</p>

                <p><a href="KNLcase/">Case Study: Profiling and Optimization on Advanced Cluster Architectures</a><br />
    This case study details how to use various profiling tools to assess computational performance and possible optimization strategies that can improve performance. 
                    This walk-through on the Stampede2 KNL nodes at TACC is generally applicable to both KNL clusters and other advanced cluster architectures.</p>


           <p><a href="JetstreamReq/">Jetstream Allocations</a><br /> 
    This topic is an overview of the application process for allocations on the Jetstream computing resource under XSEDE. It includes details about Jetstream itself,
                a description of the necessary documents which comprise an application, and advice about how to prepare a successful allocation request.</p>

 
     <p><a href="Jetstream/">Introduction to Jetstream</a><br />   
    This topic covers the basics that you need to know in order to make productive use of Jetstream, including how to access Jetstream, create and manage instances and volumes, log in to instances and transfer files.</p>

     <p><a href="JetstreamPub/">Publishing Jetstream Virtual Machines</a><br />   
    This topic covers the necessary steps for publishing a Jetstream VM image to make it permanently available to the scientific community. A published VM image can be referenced in scholarly works by means of a unique Digit Object Identifier (DOI). </p>

     <p><a href="JetstreamAPI/">Using the Jetstream APIs</a><br />   
    Jetstream’s default web interface was designed for ease of use by scientists who are new to cloud computing.  Beyond that simple interface, Jetstream also provides the more powerful OpenStack web interface as well as various command line interpreters and application programmer interfaces.  This module describes how to use these advanced Jetstream interfaces.</p>

    


        <p><a href="Comet/">Getting Started with Comet</a><br />
    The SDSC Comet system is a ~2 petaflops (PFLOPS ) Dell Linux Cluster that was put into production in April, 2015. Comet's diverse set of nodes caters to a wide variety of use cases. 
     This module is intended to insure that all users have the basic knowledge to use Comet efficiently. It contains the information needed to access the system, transfer data and code to the system, compile/link code, and submit jobs to the batch system. It also covers several examples that are well suited as Comet use cases.</p>

  
        <p><a href="Wrangler/">Introduction to Wrangler</a><br />
 Wrangler is a powerful XSEDE-allocated data analysis machine which is a collaboration between Indiana University (IU), The Texas Advanced Computing Center (TACC), and University of Chicago. 
            Wrangler has specialized hardware to aid the performance of advanced data analysis tasks. Data analytics has significantly different data access patterns and approaches compared to those used in traditional High Performance Computing (HPC).
This tutorial details the Wrangler resources and the best usage patterns to leverage its capabilities. 
            Additionally, we provide a brief survey of selected data analysis software available on Wrangler, and a primer on provisioning for your requirements.</p>

        <p><a href="SciGateMap/">Science Gateway Roadmap</a><br />
    Use the interactive decision tree to help you with the process of determining whether you need a Science Gateway and, if so, how to decide which options are best for you and your science community's needs. Explore the various paths which may be of interest to you.</p>  
                      

        <p><a href="GateAdmin/">How to Create a Science Gateway Application</a><br />
    Science Gateways serve a discipline-specific community of HPC users. This tutorial is intended for Science Gateway Administrators who are working with a fully installed and functioning Gateway and want to begin to create applications and configure the GUI. In this tutorial, we will step through the process of building an Application which will allow us to submit a job using the Gaussian computational chemistry program on the Comet supercomputer hosted at the San Diego Supercomputer Center.</p>  

        <center><h3>Parallel Computing</h3></center>


    <p><a href="APC/">Applications of Parallel Computing</a><br />
    This set of lectures is an online rendition of Applications of Parallel Computers taught by Jim Demmel at U.C. Berkeley in Spring 2012. 
    This online course is sponsored by the Extreme Science and Engineering Discovery Environment (XSEDE), and is only available 
 by logging in first through the "Login (Globus)" link or through the <a href="http://portal.xsede.org">XSEDE User Portal</a>.</p>

             <p><a href="EPS/">Engineering Parallel Software</a><br />
    This set of lectures is an online rendition ofEngineering Parallel Software taught by Kurt Keutzer at U.C. Berkeley in 2014. 
    This online course is sponsored by the Extreme Science and Engineering Discovery Environment (XSEDE), and is only available 
 by logging in first through the "Login (Globus)" link or through the <a href="http://portal.xsede.org">XSEDE User Portal</a>.</p>


    <p><a href="Parallel/">Parallel Programming Concepts and High-Performance Computing</a><br />
    Concepts concerning parallel processing and its efficient realization within different hardware and software environments.</p>
    
<a name="MPI"></a><a href="MPIP2P/"></a><a href="MPIcc/"></a><a href="MPIAdvTopics/"></a><a href="MPIoneSided/"></a>
<h3>Roadmap of MPI Topics</h3>
        <p>
            There are    five related topics on MPI in the Cornell Virtual Workshop.  
            We recommend that you work through and understand at least the topics listed under &quotessential,&quot in the  order shown.</p> 
      
        <ul><li>Essential
         
            <ul  style="PADDING-LEFT: 12px">
                <li><a href="/MPI">Message Passing Interface (MPI)</a> <br />message passing basic concepts and terminology</li>
                <li><a href="/MPIP2P">MPI Point-to-Point Communication</a><br />message passing between single MPI processes</li>
                <li><a href="/MPIcc">MPI Collective Communications</a><br />more powerful patterns among groups of MPI processes, e.g., one-to-all or functions such as gather</li>
            </ul>
            </li>
        <li>Optional
            <ul  style="PADDING-LEFT: 12px">
                <li><a href="/MPIAdvTopics">MPI Advanced Topics</a><br />useful additional techniques, e.g., overlaying your data with datatypes to speed message passing</li>
                <li><a href="/MPIoneSided">MPI One-Sided Communication</a><br />sending messages via RDMA</li>
            </ul>
            </li>
              </ul>
<!---
    
    <p><a href="MPI/">Message Passing Interface (MPI)</a><br />
    MPI is a de facto standard specifying the interface and functionality of a message-passing library, a collection of routines for facilitating communication (exchange of data and synchronization) among the tasks in a distributed memory parallel program. MPI is the first standard and portable message passing library that offers good performance.</p>   

    <p><a href="MPIP2P/">MPI Point-to-Point Communication</a><br />
    This module details and differentiates the various types of point-to-point communication available in MPI.  Point-to-point communication involves transmission of a message between a pair of processes, as opposed to collective communication, which involves a group of processes.</p>

    <p><a href="MPIcc/">MPI Collective Communications</a><br />
    The purpose of collective communication is to manipulate a shared piece or set of information.  In this module, we introduce these routines in three categories: synchronization, data movement, and global computation.</p>


    <p><a href="MPIAdvTopics/">MPI Advanced Topics</a><br />
    This module will introduce you to some of the advanced capabilities of MPI beyond ordinary message passing, including how to customize your environment in the following areas: derived datatypes; groups of processes and their associated communicators; virtual topologies among processes; and parallel I/O using MPI-IO.  Application to specific architectures such as Stampede2 will be discussed.</p>

    <p><a href="MPIoneSided/">MPI One-Sided Communication</a><br />
    One-sided communication provides natural access to Remote Direct Memory Access (RDMA) functionality that is provided by low-latency interconnect fabrics such as InfiniBand. In this module, we will introduce the various components of MPI RDMA and how to use them.</p>
--->

    <p><a href="ParallelIO/">Parallel I/O</a><br />
    This module presents basic concepts and techniques that will allow your application to take advantage of parallel I/O to increase throughput and improve scalability. Emphasis is placed on the Lustre parallel file system, and on MPI-IO as a fundamental API.</p>

                <p><a href="ParIOLib/">Parallel I/O Libraries Part 1</a><br />
    Many scientific applications work with structured data, and in many cases such data require pre- and post-processing. The existing I/O libraries not only allow applications to work with portable, self-describing file formats, but also provide tools to process the data. In Part 1 of this topic, we introduce Parallel NetCDF, a parallel I/O library that can be used to increase the throughput and efficiency of I/O bound applications.</p>

                         <p><a href="ParIOLib2/">Parallel I/O Libraries Part 2</a><br />
    In this topic, we introduce parallel I/O libraries and techniques that can be used to increase the throughput and efficiency of I/O bound applications. Part 2 covers PHDF5 and gives a brief introduction to ADIOS.</p>


    <p><a href="OpenMP/">OpenMP</a><br />
    In the shared-memory  environment that Stampede2 has on each node, it is much easier to introduce parallelism into your code with OpenMP than to do pthread programming from scratch or to use MPI. 
         This module introduces OpenMP and describes how to use it.</p>

    <p><a href="Hybrid/">Hybrid Programming with OpenMP and MPI </a><br />
    In hybrid programming, the goal is to combine techniques from OpenMP and 
MPI to create a high-performance parallel code that is better tailored for 
the non-uniform and heterogeneous memory access characteristics of Stampede2.  To meet this 
goal, it is necessary to understand the effects of processor affinity and 
memory allocation policy, and to exert some control over them.</p>

    <p><a href="MIC/">MIC</a><br />
    The Xeon Phi coprocessor is a system on a PCIe card designed to provide high levels of floating point performance for highly parallel HPC code. Its architecture is known as Many Integrated Core (MIC).
    This module describes the MIC architecture behind the Xeon Phi, its performance characteristics, how and when to run code on the coprocessors available within Stampede in order to best take advantage of the resources available.</p>
    
        <p><a href="MostOfMIC/">How to Make the Most of MIC</a><br />
   This module focuses on a question of high interest to many HPC users: what changes might I need to make to my program, or even to my algorithm, so my application can make good use of many-core processors such as the Intel Xeon Phi on Stampede? To answer this, we consider just the main characteristics of Intel’s Many Integrated Core (MIC) architecture, along with their implications for how a MIC-enabled code should be put together.</p>
    


          <center><h3>Code Improvement</h3></center>

    <p><a href="Profiling/">Profiling and Debugging</a><br />
    This module describes how to obtain detailed performance data for jobs on Stampede2. It also discusses tools and techniques for online parallel application debugging.</p>
    
    <p><a href="Optimization/">Scalability</a> <br />
    When you request an allocation on a large HPC resource like Stampede2, you need to demonstrate that your code is scalable. 
        This module will help you understand what algorithmic and design choices are most likely to help your application perform well in parallel.
         It will also guide you in figuring out which choices actually do make it scale better on Stampede2 and other machines of its class.</p>

    <p><a href="CodeOpt/">Code Optimization</a> <br />
     There are a few simple things one can do in one's code to make the most of typical computing resources, up to and including high performance computing (HPC) resources. This module covers basic aspects of code optimization that can have a big impact, as well as common performance pitfalls to avoid. The module also explains the main features of microprocessor architecture and how they relate to the performance of compiled code.</p>


<p><a href="compsteer/">Computational Steering</a><br />
    This module provides an introduction to what computational steering is, the potential benefits from using it, and examples on how you can integrate steering into your existing application.</p>
    
    <p><a href="usecases/">Use Cases</a><br />
    This module captures Felix Bachmann&#039;s presentation at XSEDE12 on Use Cases and Quality Attribute Scenarios.</p>
    


        <p><a href="vector/">Vectorization</a><br />
     Vectorization is a process by which mathematical operations found in tight loops in scientific code are executed in parallel on special vector hardware found in CPUs and coprocessors.  This module describes the vectorization process as it relates to computing hardware, compilers, and coding practices. </p>


        <p><a href="Checkpoint/">Checkpointing</a><br />
        In this module we'll explore several categories of C/R solutions and go into examples and exercises of some implementations that are particularly well-suited for high-performance computing.</p>
   
        <p><a href="HDF5forCR/">HDF5 for Checkpoint/Restart</a><br />
HDF5 (the Hierarchical Data Format, version 5) is a library, data model, and file format designed for managing data, especially in HPC where efficient I/O is a high priority. 
        While there are many ways in which HDF5 can be used for modeling data and creating file formats, 
        in this module we focus on how to use HDF5 within a program to save the relevant parts of state needed in order to resume the application with minimal loss of CPU time.</p>

                    <p><a href="CometSing/">Singularity on Comet</a><br />
This tutorial is intended to help users get up and running quickly with Singularity on XSEDE's Comet supercomputer (but it can also be adapted to other XSEDE systems with minor differences). It provides a brief overview of Singularity, how to build your own containers locally and move them to Comet, how to submit Singularity jobs to run on Comet, and a simple exercise on how to run the popular deep learning application Tensorflow with Singularity on Comet.</p>

   

          <center><h3>Data Analysis</h3></center>

    <p><a href="GlobusXfer/">Globus Data Transfer</a><br />
    Globus is a research data management system that provides fast, reliable and secure file transfers and sharing. This topic discusses the following:  Procedures for creating and configuring Globus accounts, transferring files using the Globus web interface and best practices for using Globus on XSEDE compute resources.</p>

        <p><a href="GlobusXfer2/">Advanced Globus Data Transfer</a><br />
    Globus is a research data management system that provides fast, reliable and secure file transfers and sharing.  This topic discusses the following advanced Globus data transfer subjects:  How the Globus Command Line Interface (CLI) can be used to perform data transfer tasks from a shell or a script, and how to create and configure a Globus endpoint on a personal computer.</p>


    <p><a href="LargeVis/">Large Data Visualization</a><br />
    This module gives an introduction to some concepts of visualization with a focus on the parallel computing techniques used to handle large datasets.</p>

    <p><a href="ParaView/">ParaView</a><br />
    ParaView is a visualization application highly capable for computational fluid dynamics and other subjects. It is open source and can run in parallel on Stampede2. This module includes a lab which covers visualization of a sample dataset both on a local computer and on TACC resources.</p>

            
    <p><a href="ParaViewAdv/">ParaView - Advanced</a><br />
    This topic presents introductions to several advanced features of the ParaView visualization software.  It covers techniques for exploring data, creating animations, using Python scripts to add new functionality, integrating ParaView with simulation software and advanced rendering features.</p>


   <p><a href="DataTransfer/">Data Transfer</a><br />
    There are several utilities that can perform the essential task of transferring data and/or code between your workstation or cloud storage and a larger computing resource. 
	The one you choose can depend on the amount of data to be transferred and your need for speed, the ease of invoking the utility, its ability to sync data stored in two places, 
	and the ability to use the utility in a script. This topic presents some popular data transfer options and their pros and cons, as well as ways to make your transfers faster.</p>

    <p><a href="Databases/">Relational Databases</a><br />
    This module provides an introduction to relational databases, the most common type of database and what you are most likely to find available at an XSEDE site.</p>



    <p><a href="MapReduce/">MapReduce</a><br />
This module describes the basic MapReduce paradigm, the Hadoop MapReduce framework, and techniques for running MapReduce frameworks on HPC resources.</p>

   




    
<!-- END MAIN -->

<hr class="CU" />



    <center><span id="lblBackButton"></span></center>
        

        
        
        
</div>
      
</div>
<span id="lblError"></span>

<hr class="CU" />

<!-- BEGIN FOOTER -->
    <div id="footer">
        <div id="footer-content" align="center">
            &copy;
                        <script type="text/javascript">
                        <!--
                            var d = new Date();
                            document.write(d.getFullYear());
                        //-->
            </script>

              <a href="https://www.cornell.edu/">Cornell University</a> | <a href="https://www.cac.cornell.edu/">Cornell University Center for Advanced Computing</a> | <a href="https://www.cac.cornell.edu/copyright.aspx">Copyright Statement</a> | <a href="https://cvw.cac.cornell.edu/terminology.aspx">Terminology Statement</a>
        </div>
    </div>
<!-- END FOOTER -->
    </form>

<!-- Start of StatCounter Code -->
<script type="text/javascript">
var sc_project=4742968; 
var sc_invisible=1; 
var sc_partition=54; 
var sc_click_stat=1; 
var sc_security="9445d005"; 
var sc_https=1; 
var scJsHost = (("https:" == document.location.protocol) ?
"https://secure." : "http://www.");
document.write("<sc"+"ript type='text/javascript' src='" +
scJsHost +
"statcounter.com/counter/counter.js'></"+"script>");</script>

<noscript><div class="statcounter"><a title="joomla 1.5
stats" href="http://www.statcounter.com/joomla/"
target="_blank"><img class="statcounter"
src="https://c.statcounter.com/4742968/0/9445d005/1/"
alt="joomla 1.5 stats" ></a></div></noscript>
<!-- End of StatCounter Code -->



</body>
</html>